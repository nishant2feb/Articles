---
title: "Data Science (Data(Acquisition, Visualization, Preparation) -> Modelling -> Evaluation)"
author: "Nishant"
output:
  html_document:
    number_sections: true
    toc: true
    fig_width: 10
    code_folding: hide
    fig_height: 4.5
    theme: cosmo
    highlight: tango
---


# Introduction

Hi, Welcome to my data science's exploration kernel based on the data provided by [Machine Learning and Data Science Survey](https://www.kaggle.com/kaggle/kaggle-survey-2018/home) in which my inputs are also present. 
It is very exciting to explore about your community and present the insights. I will explore the data in a way that a model being built in different organizations. The stages involved are 

* Data (Acquisition, Visualization and Preparation)
* Modelling
* Evaluation

The data present with us have three file, two will be utilized for extracting data and one for the information of the chracteristics.

- *multiple choice responses* to questions with limited answer options
- *free-form responses* to open questions

## Derived Summary

Apart from my evaluation scenario here are few summarized facts about the developers derived from various kernels which I am not covering in this kernel.

- **Country of Residence, Gender, Age:** The demographics show that the *US and India had by far the most respondents*, followed by China, Russia, Brazil, and Germany. Africa as well as parts of western Asia and Central America are underrepresented. The survey shows a *predominantly male* community with only about 17% female participation. The age distribution is skewed towards the younger cohorts in their 20s or early 30s. Among the top responding countries, *India has significantly younger participant than the US*.

- **Education & Profession:** Most respondents have a *Bachelor's or Master's degree* from a list of academic fields that is dominated by *Computer Science*, followed by *Engineering* and *Maths & Statistics*. Many of those with a Doctoral degree have a Physics/Astronomy background. The *largest professional cohort are students*, followed by the industry roles of Data Scientist, Software Engineer, and Data Analyst.

- **Experience:** Most respondents have been *in their current role for less than 3 years*, many less than 1 year. Similarly, most people have *coding experience of less than 5 years*, with 1-2 years being the most common answer, and *less than 2 years of ML experience*.


# Data(Acquisition, Visualization, Preparation)

## Data Acquisition
We all know the zero point of any analysis is data or atleast data domain knowledge if you are drawing some bayesian inferences.
So if we are getting started we should start with data related facts. So I will begin with data acquiring or the sources from data being extracted for the data models.

*Q29 of multiple choice questions posses information regarding relational databases that are used by the developers in last five years.* I will consider the information that the databases are used to acquire data.

Q29 has `1079` responses in which the reponses excluded are; age group 0-17, never written code, not used cloud providers.


```{r message=FALSE, warning=FALSE}
library(plotly)
library(ggplot2)
library(dplyr)
library(broom)
library(tidyverse)

multipleChoice <- read_csv("multipleChoiceResponses.csv")
Col_palete = colorRampPalette(c("blue", "green", "orange", "red"))(100)

DataAquisitionRD <- multipleChoice%>%  
select(Q7,starts_with("Q29"), -Q29_OTHER_TEXT) %>%
  gather(key =  RD_Attr, value = RD, -Q7) %>%
  filter(!is.na(RD)) %>%
  filter(RD!="None")%>%
  select(Q7,RD)%>%
  group_by(Q7, RD)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

DataAquisitionRD%>%
  ggplot(aes(x = Q7, y = RD))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Relational Databases")



```

Looking at the relation database distribution we can easily see `MySQL`, `PostgresSQL` and `SQLite` are on the top.

*Similarly lets look into bigdata and analytics product.*
Q30 of multiple choice questions contains the reponse for bigdata and analytics.

```{r fig.height= 5}

BigDataAnalytics <- multipleChoice%>%  
select(Q7, starts_with("Q30"), -Q30_OTHER_TEXT) %>%
  gather(key =  BD_Attr, value = BD, -Q7) %>%
  filter(!is.na(BD)) %>%
  filter(BD!="None")%>%
  select(Q7,BD)%>%
  group_by(Q7, BD)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

BigDataAnalytics%>%
  ggplot(aes(x = Q7, y = BD))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Big Data Analytics Platforms")

```

From the view we can see that more than 1/5th developers and modelers are not using any bigdata analytics products, the products that are leading are `Google BigQuery`, `AWS Redshift` and `Databricks`.

*Lets look at the data type used most often.*
Q31 contains the response.

```{r}

DataType <-multipleChoice%>%  
select(Q7, starts_with("Q31"), -Q31_OTHER_TEXT) %>%
  gather(key =  DT_Attr, value = DT, -Q7) %>%
  filter(!is.na(DT)) %>%
  filter(DT!="None")%>%
  select(Q7,DT)%>%
  group_by(Q7, DT)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

DataType%>%
  ggplot(aes(x = Q7, y = DT))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Data Type")

```

*Lets look at the data type that's being used recently.*
Q32 contains the reponse.

```{r}

DataTypeRecent <- multipleChoice%>%  
select(Q7, starts_with("Q32"), -Q32_OTHER) %>%
  gather(key =  DTR_Attr, value = DTR, -Q7) %>%
  filter(!is.na(DTR)) %>%
  filter(DTR!="None")%>%
  select(Q7,DTR)%>%
  group_by(Q7, DTR)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

DataTypeRecent%>%
  ggplot(aes(x = Q7, y = DTR))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Data Type recent")


```

*Lets look at public dataset sources.*
Q33 contains the response for the public datasets.

```{r}

PublicDataset <- multipleChoice%>%  
select(Q7, starts_with("Q33"), -Q33_OTHER_TEXT) %>%
  gather(key =  PD_Attr, value = PD, -Q7) %>%
  filter(!is.na(PD)) %>%
  filter(PD!="None")%>%
  select(Q7,PD)%>%
  group_by(Q7, PD)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

PublicDataset%>%
  ggplot(aes(x = Q7, y = PD))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Public Datasets")+
  scale_y_discrete(label = function(y) abbreviate(y, minlength = 30))

```

*Lets look at the time spent in gathering data.*

```{r message=FALSE, warning=FALSE, fig.height=8}

GatheringData <- multipleChoice%>%  
select(Q7, Q34_Part_1) %>%
  filter(!is.na(Q34_Part_1)) %>%
  filter(!is.na(Q7))%>%
  mutate(Q34_Part_1 = as.numeric(Q34_Part_1))%>%
  group_by(Q7, Q34_Part_1)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

GatheringData%>%
  ggplot(aes(x = Q7, y = as.factor(Q34_Part_1)))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "% of time spent")


```


## Data Visualization

Lets look at the visulaization libraries used in last five years.

```{r}

VizLib <- multipleChoice%>%  
select(Q7, starts_with("Q21"), -Q21_OTHER_TEXT) %>%
  gather(key =  VL_Attr, value = VL, -Q7) %>%
  filter(!is.na(VL)) %>%
  filter(VL!="None")%>%
  select(Q7,VL)%>%
  group_by(Q7, VL)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

VizLib%>%
  ggplot(aes(x = Q7, y = VL))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Visualization libraries")

```

Lets look at the visualization libraries used often in the choices.

```{r}

VizLibOften <- multipleChoice%>%  
select(Q7, starts_with("Q22"), -Q22_OTHER_TEXT) %>%
  gather(key =  VLO_Attr, value = VLO, -Q7) %>%
  filter(!is.na(VLO)) %>%
  filter(VLO!="None")%>%
  select(Q7,VLO)%>%
  group_by(Q7, VLO)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

VizLibOften%>%
  ggplot(aes(x = Q7, y = VLO))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Often Used VL")



```

*Lets look at the time spent in visualizing data.*

```{r, fig.height=8}

VisualizingTime <- multipleChoice%>%  
select(Q7, Q34_Part_3) %>%
  filter(!is.na(Q34_Part_3)) %>%
  filter(!is.na(Q7))%>%
  mutate(Q34_Part_3 = as.numeric(Q34_Part_3))%>%
  group_by(Q7, Q34_Part_3)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

VisualizingTime%>%
  ggplot(aes(x = Q7, y = as.factor(Q34_Part_3)))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "% of Time Spent")



```


## Data Preparation

*Lets look at the primary tool used to analyse data.*

```{r}

ToolAnalyse <- multipleChoice%>%  
select(Q7, Q12_MULTIPLE_CHOICE) %>%
  filter(!is.na(Q12_MULTIPLE_CHOICE)) %>%
  filter(!is.na(Q7))%>%
  group_by(Q7, Q12_MULTIPLE_CHOICE)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()

ToolAnalyse%>%
  ggplot(aes(x = Q7, y = Q12_MULTIPLE_CHOICE))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_discrete(label = function(x) abbreviate(x, minlength = 20))+
  scale_y_discrete(label = function(y) abbreviate(y, minlength = 20))+
  labs(x = "Oraginizations", y = "Tools for Analysis")


```


*Lets look at the hosted notebooks used in last 5 years.*

```{r}

HostedNotebooks <- multipleChoice%>%  
select(Q7,starts_with("Q14"), -Q14_OTHER_TEXT) %>%
  gather(key =  HN_Attr, value = HN, -Q7) %>%
  filter(!is.na(HN)) %>%
  filter(HN!="None")%>%
  select(Q7,HN)%>%
  group_by(Q7, HN)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

HostedNotebooks%>%
  ggplot(aes(x = Q7, y = HN))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Notebooks")



```

*Lets look at the data cleaning part.*

```{r message=FALSE, warning=FALSE, fig.height=8}

CleaningData <- multipleChoice%>%  
select(Q7, Q34_Part_2) %>%
  filter(!is.na(Q34_Part_2)) %>%
  filter(!is.na(Q7))%>%
  mutate(Q34_Part_2 = as.numeric(Q34_Part_2))%>%
  group_by(Q7, Q34_Part_2)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

CleaningData%>%
  ggplot(aes(x = Q7, y = as.factor(Q34_Part_2)))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "% of Time Spent")



```


# Modelling

In previous section I tried to capture the processes related to data that are `acquisition`, `visualization` and `preparation`. Now we look at the section of modelling.

Q19 possess the response for the machine learning framework, so lets look by visualizing it.

```{r}

MLFramework <- multipleChoice%>%  
select(Q7,starts_with("Q19"), -Q19_OTHER_TEXT) %>%
  gather(key =  MLF_Attr, value = MLF, -Q7) %>%
  filter(!is.na(MLF)) %>%
  filter(MLF!="None")%>%
  select(Q7,MLF)%>%
  group_by(Q7, MLF)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

MLFramework%>%
  ggplot(aes(x = Q7, y = MLF))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Machine Learning Framework")



```


Q28 possess the response for machine learning products that are used in last five years.

```{r fig.height= 10}

MLproducts <- multipleChoice%>%  
select(Q7,starts_with("Q28"), -Q28_OTHER_TEXT) %>%
  gather(key =  MLP_Attr, value = MLP, -Q7) %>%
  filter(!is.na(MLP)) %>%
  filter(MLP!="None")%>%
  select(Q7,MLP)%>%
  group_by(Q7, MLP)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

MLproducts%>%
  ggplot(aes(x = Q7, y = MLP))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "Big Data Analytics Platforms")


```


Q34 contains the reponse for thetime spent in building Models.

```{r message=FALSE, warning=FALSE}


CleaningData <- multipleChoice%>%  
select(Q7, Q34_Part_4) %>%
  filter(!is.na(Q34_Part_4)) %>%
  filter(!is.na(Q7))%>%
  mutate(Q34_Part_4 = as.numeric(Q34_Part_4))%>%
  group_by(Q7, Q34_Part_4)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

CleaningData%>%
  ggplot(aes(x = Q7, y = as.factor(Q34_Part_4)))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "% time spent")

```


Q43 possess responses for the time spent for exploring unfair bias dataset.

```{r}

BiasData <- multipleChoice%>%  
select(Q7, Q43) %>%
  filter(!is.na(Q43)) %>%
  filter(!is.na(Q7))%>%
  group_by(Q7, Q43)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

BiasData%>%
  ggplot(aes(x = Q7, y = as.factor(Q43)))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x = "Oraginizations", y = "% time spent")




```

Q44 Possess response for the difficulties faced in exploring the biased data.

```{r}

BiasDataDifficulty <- multipleChoice%>%  
select(Q7,starts_with("Q44")) %>%
  gather(key =  BDD_Attr, value = BDD, -Q7) %>%
  filter(!is.na(BDD)) %>%
  filter(BDD!="None")%>%
  select(Q7,BDD)%>%
  group_by(Q7, BDD)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

BiasDataDifficulty%>%
  ggplot(aes(x = Q7, y = BDD))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_discrete(label = function(y) abbreviate(y, minlength = 20))+
  labs(x = "Oraginizations", y = "Difficulties in exploring bias  data")


```




# Evaluation 

Now we look at the last phase that is evaluation, Lets look at the evaluating factors.

Q42 possess the response for the factors that are considered for the sucess or failure of a model in different organization.


```{r}


EvaluationFactors <- multipleChoice%>%  
select(Q7,starts_with("Q42"), -Q42_OTHER_TEXT) %>%
  gather(key =  EF_Attr, value = EF, -Q7) %>%
  filter(!is.na(EF)) %>%
  filter(EF!="None")%>%
  select(Q7,EF)%>%
  group_by(Q7, EF)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

EvaluationFactors%>%
  ggplot(aes(x = Q7, y = EF))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_discrete(label = function(y) abbreviate(y, minlength = 30))+
  labs(x = "Oraginizations", y = "Evaluation Factors")


```

Now lets look at the methods used for explaining or interpreting the ML models.

Q47 possess the responses about the method.

```{r, fig.height=8}

EvaluationFactors <- multipleChoice%>%  
select(Q7,starts_with("Q47")) %>%
  gather(key =  ME_Attr, value = ME, -Q7) %>%
  filter(!is.na(ME)) %>%
  filter(ME!="None")%>%
  select(Q7,ME)%>%
  group_by(Q7, ME)%>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()%>%
  filter(Count != 1)

EvaluationFactors%>%
  ggplot(aes(x = Q7, y = ME))+
  geom_tile(aes(fill = Count))+
  geom_text(aes(label = Count))+
  scale_fill_gradientn(colours = Col_palete)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_discrete(label = function(y) abbreviate(y, minlength = 30))+
  labs(x = "Oraginizations", y = "Methods for interpreting the model")

```





More updates to come in correlating and summarizing the procedures....

